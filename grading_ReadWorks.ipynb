{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from math import isnan\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* topic detection literature - extract features of plain text.\n",
    "* spelling correction\n",
    "* narrow down to manual grading. Flagging if existing words in the string are below a system of certainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answers = pd.read_excel('litmus_results_trial1.xlsx').set_index('student_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_code\n",
       "FKYGSM    2\n",
       "MH6FDC    2\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers.groupby('class_code').nunique()['Type'][answers.groupby('class_code').nunique()['Type']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "answers_subset = answers.dropna(how='all',subset=['question_id_11459_answer',\n",
    "                                                  'question_id_11460_answer',\n",
    "                                                  'question_id_11461_answer'])\n",
    "\n",
    "answers_graded = answers.dropna(how='any',subset=['question_id_11459_score',\n",
    "                                                  'question_id_11460_score',\n",
    "                                                  'question_id_11461_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarangof/anaconda/lib/python2.7/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "answers_graded.loc[:,'question_id_11459_score'] = answers_graded['question_id_11459_score'].astype('str')\n",
    "answers_graded.loc[:,'question_id_11460_score'] = answers_graded['question_id_11460_score'].astype('str')\n",
    "answers_graded.loc[:,'question_id_11461_score'] = answers_graded['question_id_11461_score'].astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_59, X_test_59, y_train_59, y_test_59 = train_test_split(answers_graded['question_id_11460_answer'], \n",
    "                                                        answers_graded['question_id_11460_score'], \n",
    "                                                        test_size=0.2, \n",
    "                                                        random_state=42)\n",
    "\n",
    "X_train_60, X_test_60, y_train_60, y_test_60 = train_test_split(answers_graded['question_id_11460_answer'], \n",
    "                                                        answers_graded['question_id_11460_score'], \n",
    "                                                        test_size=0.2, \n",
    "                                                        random_state=42)\n",
    "\n",
    "X_train_61, X_test_61, y_train_61, y_test_61 = train_test_split(answers_graded['question_id_11460_answer'], \n",
    "                                                        answers_graded['question_id_11460_score'], \n",
    "                                                        test_size=0.2, \n",
    "                                                        random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2824"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answers_graded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1631"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answers_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform_na(text):\n",
    "    try: \n",
    "        if isnan(text):\n",
    "            return ''\n",
    "        else:\n",
    "            return unicode(text)\n",
    "    except TypeError:\n",
    "        return unicode(text)\n",
    "\n",
    "training_data_59 = [{'score':x,'text':transform_na(y)} for x,y in zip(answers_graded.loc[X_train_59.index.values]['question_id_11459_score'].values,\n",
    "                                                                      answers_graded.loc[X_train_59.index.values]['question_id_11459_answer'].values)]\n",
    "\n",
    "testing_data_59 = [{'score':x,'text':transform_na(y)} for x,y in zip(answers_graded.loc[X_test_59.index.values]['question_id_11459_score'].values,\n",
    "                                                                     answers_graded.loc[X_test_59.index.values]['question_id_11459_answer'].values)]\n",
    "\n",
    "training_data_60 = [{'score':x,'text':transform_na(y)} for x,y in zip(answers_graded.loc[X_train_60.index.values]['question_id_11460_score'].values,\n",
    "                                                                      answers_graded.loc[X_train_60.index.values]['question_id_11460_answer'].values)]\n",
    "\n",
    "testing_data_60 = [{'score':x,'text':transform_na(y)} for x,y in zip(answers_graded.loc[X_test_60.index.values]['question_id_11460_score'].values,\n",
    "                                                                     answers_graded.loc[X_test_60.index.values]['question_id_11460_answer'].values)]\n",
    "\n",
    "training_data_61 = [{'score':x,'text':transform_na(y)} for x,y in zip(answers_graded.loc[X_train_61.index.values]['question_id_11461_score'].values,\n",
    "                                                                      answers_graded.loc[X_train_61.index.values]['question_id_11461_answer'].values)]\n",
    "\n",
    "testing_data_61 = [{'score':x,'text':transform_na(y)} for x,y in zip(answers_graded.loc[X_test_61.index.values]['question_id_11461_score'].values,\n",
    "                                                                     answers_graded.loc[X_test_61.index.values]['question_id_11461_answer'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ignore_words = list(set(list(string.punctuation))-set(['?','\"'])) #+ ['?'] +  stopwords.words('english')\n",
    "\n",
    "def define_elements(training_data):\n",
    "    words = []\n",
    "    classes = []\n",
    "    documents = []\n",
    "    for pattern in training_data:\n",
    "        w_pre = []\n",
    "        split_words = pattern['text'].split(\" \")\n",
    "        for wrd in split_words:\n",
    "            wrd = \"\".join(wrd.split(\"'\"))\n",
    "            wrd = \"\".join(wrd.split(\"`\"))\n",
    "            wrd = \"\".join(wrd.split(\"-\"))\n",
    "            wrd = \"\".join(wrd.split(\"`\"))\n",
    "            w_pre.append(wrd)\n",
    "            \n",
    "        #w = nltk.word_tokenize(w_pre)\n",
    "        # add to our words list\n",
    "        words.extend(w_pre)\n",
    "        # add to documents in our corpus\n",
    "        documents.append((w_pre, pattern['score']))\n",
    "        # add to our classes list\n",
    "        if pattern['score'] not in classes:\n",
    "            classes.append(pattern['score'])\n",
    "    return words,documents,classes\n",
    "\n",
    "words_59, documents_59, classes_59 = define_elements(training_data_59)\n",
    "words_60, documents_60, classes_60 = define_elements(training_data_60)\n",
    "words_61, documents_61, classes_61 = define_elements(training_data_61)\n",
    "\n",
    "# stem and lower each word and remove duplicates\n",
    "#words_59 = [stemmer.stem(w.lower()) for w in words_59 if w not in ignore_words]\n",
    "words_59 = [w.lower() for w in words_59 if w not in ignore_words]\n",
    "words_59 = list(set(words_59))\n",
    "#words_60 = [stemmer.stem(w.lower()) for w in words_60 if w not in ignore_words]\n",
    "words_60 = [w.lower() for w in words_60 if w not in ignore_words]\n",
    "words_60 = list(set(words_60))\n",
    "#words_61 = [stemmer.stem(w.lower()) for w in words_61 if w not in ignore_words]\n",
    "words_61 = [w.lower() for w in words_61 if w not in ignore_words]\n",
    "words_61 = list(set(words_61))\n",
    "\n",
    "# remove duplicates\n",
    "classes_59 = list(set(classes_59))\n",
    "classes_60 = list(set(classes_60))\n",
    "classes_61 = list(set(classes_61))\n",
    "\n",
    "#print (len(documents), \"documents\")\n",
    "#print (len(classes), \"classes\", classes)\n",
    "#print (len(words), \"unique stemmed words\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'',\n",
       " u'go',\n",
       " u'young',\n",
       " u'passage',\n",
       " u'to',\n",
       " u'anddancing',\n",
       " u'dressing',\n",
       " u'mother,',\n",
       " u'song',\n",
       " u'very',\n",
       " u'trouble',\n",
       " u'begening',\n",
       " u'danicing.',\n",
       " u'her,\"why',\n",
       " u'makebelieve[par.1]',\n",
       " u'nine.',\n",
       " u'ups',\n",
       " u'talked',\n",
       " u'says',\n",
       " u'her.',\n",
       " u'her,',\n",
       " u'bluederes',\n",
       " u'purtending',\n",
       " u'blue',\n",
       " u'believe,and',\n",
       " u'what',\n",
       " u'holdiding',\n",
       " u'version',\n",
       " u'told',\n",
       " u'hey,monica',\n",
       " u'here',\n",
       " u'hers',\n",
       " u'sing',\n",
       " u'great',\n",
       " u'kids',\n",
       " u'blueberrys',\n",
       " u'my',\n",
       " u'childeren]',\n",
       " u'arent',\n",
       " u'pick',\n",
       " u'store.\"',\n",
       " u'makebalieve',\n",
       " u'love',\n",
       " u'suddenly',\n",
       " u'stop/quit.',\n",
       " u'kichion',\n",
       " u'\\u201cyeah\\u2026but',\n",
       " u'singing',\n",
       " u'story.',\n",
       " u'story,',\n",
       " u'believe?',\n",
       " u'would',\n",
       " u'\"arent',\n",
       " u'right?',\n",
       " u'few',\n",
       " u'believe.',\n",
       " u'music',\n",
       " u'makebelive.\"',\n",
       " u'right.',\n",
       " u'type',\n",
       " u'blueberry',\n",
       " u'singing.',\n",
       " u'phone',\n",
       " u'this',\n",
       " u'pretend',\n",
       " u'movies',\n",
       " u'can',\n",
       " u'making',\n",
       " u'didnt',\n",
       " u'that\\xb4s',\n",
       " u'monica',\n",
       " u'makebe?\"',\n",
       " u'allowed',\n",
       " u'bielive',\n",
       " u'end',\n",
       " u'said,',\n",
       " u'begging',\n",
       " u'after',\n",
       " u'tipped',\n",
       " u'mad',\n",
       " u'mam',\n",
       " u'a',\n",
       " u'text,\\u201caren\\u2019t',\n",
       " u'hug.',\n",
       " u'lines',\n",
       " u'music.',\n",
       " u'make',\n",
       " u'help',\n",
       " u'\"id',\n",
       " u'mom.',\n",
       " u'mom,',\n",
       " u'before',\n",
       " u'makebeileve',\n",
       " u'better',\n",
       " u'rock.',\n",
       " u'[why',\n",
       " u'listing',\n",
       " u'stopped.',\n",
       " u'morther',\n",
       " u'then',\n",
       " u'someone',\n",
       " u'moms',\n",
       " u'shetells',\n",
       " u'they',\n",
       " u'not',\n",
       " u'blueberries.',\n",
       " u'now',\n",
       " u'micro',\n",
       " u'stopped',\n",
       " u'rock',\n",
       " u'side',\n",
       " u'doing',\n",
       " u'house',\n",
       " u'right.\"',\n",
       " u'out',\n",
       " u'living',\n",
       " u'diddent',\n",
       " u'berrys',\n",
       " u'makingbelieve?',\n",
       " u'bleave',\n",
       " u'rock,',\n",
       " u'got',\n",
       " u'dancing,',\n",
       " u'dancing.',\n",
       " u'little',\n",
       " u'ask',\n",
       " u'beginning',\n",
       " u'could',\n",
       " u'thing',\n",
       " u'think',\n",
       " u'first',\n",
       " u'dont',\n",
       " u'hearing',\n",
       " u'done',\n",
       " u'littlie',\n",
       " u'story',\n",
       " u'\"',\n",
       " u'caught',\n",
       " u'needed',\n",
       " u'playingmakebelieve?\"',\n",
       " u'too',\n",
       " u'store',\n",
       " u'that',\n",
       " u'makebelieive,',\n",
       " u'singingand',\n",
       " u'was,',\n",
       " u'believe',\n",
       " u'than',\n",
       " u'11',\n",
       " u'loved',\n",
       " u'aren\\u2019t',\n",
       " u'were',\n",
       " u'nervase',\n",
       " u'old.',\n",
       " u'and',\n",
       " u'sees',\n",
       " u'have',\n",
       " u'seen',\n",
       " u'saw',\n",
       " u'tells',\n",
       " u'microphone',\n",
       " u'dancing',\n",
       " u'\\u201caren\\u2019t',\n",
       " u'also',\n",
       " u'belive.',\n",
       " u'givenup',\n",
       " u'makebelieve',\n",
       " u'play',\n",
       " u'though',\n",
       " u'who',\n",
       " u'that.',\n",
       " u'age.',\n",
       " u'nothing',\n",
       " u'beleve',\n",
       " u'why',\n",
       " u'fills',\n",
       " u'playing',\n",
       " u'clean',\n",
       " u'anwsered',\n",
       " u'sing.',\n",
       " u'annoyed',\n",
       " u'star?.',\n",
       " u'probbly',\n",
       " u'craziness',\n",
       " u'beleive.',\n",
       " u'going',\n",
       " u'believing',\n",
       " u'over',\n",
       " u'do',\n",
       " u'dancing\"arent',\n",
       " u'get',\n",
       " u'stop',\n",
       " u'stor',\n",
       " u'pretending',\n",
       " u'believe?\"',\n",
       " u'she',\n",
       " u'them.',\n",
       " u'makebelieve.',\n",
       " u'.if',\n",
       " u'asked,',\n",
       " u'makebelieve?',\n",
       " u'see',\n",
       " u'are',\n",
       " u'best',\n",
       " u'sead',\n",
       " u'said',\n",
       " u'says\"arent',\n",
       " u'this.\\u201d',\n",
       " u'jumped',\n",
       " u'please',\n",
       " u'we',\n",
       " u'never',\n",
       " u'labor?',\n",
       " u'kicking',\n",
       " u'picking',\n",
       " u'kitchen',\n",
       " u'monicas',\n",
       " u'stops.',\n",
       " u'askes',\n",
       " u'according',\n",
       " u'mop.',\n",
       " u'farmer.',\n",
       " u'asked',\n",
       " u'makebelieve?\".',\n",
       " u'liked',\n",
       " u'likes',\n",
       " u'humming',\n",
       " u'quit',\n",
       " u'now.',\n",
       " u'danceing',\n",
       " u'acting?',\n",
       " u'asks',\n",
       " u'\"you',\n",
       " u'west',\n",
       " u'whos',\n",
       " u'anwser',\n",
       " u'now?',\n",
       " u'acting.',\n",
       " u'\\u201ci',\n",
       " u'else',\n",
       " u'it.',\n",
       " u'will',\n",
       " u'while',\n",
       " u'animated',\n",
       " u'arentyou',\n",
       " u'where.',\n",
       " u'...',\n",
       " u'almost',\n",
       " u'is',\n",
       " u'it',\n",
       " u'middle',\n",
       " u'in',\n",
       " u'is.hermotherlovewestsidestory.',\n",
       " u'houm.',\n",
       " u'if',\n",
       " u'grown',\n",
       " u'makebelieve\".',\n",
       " u'lave',\n",
       " u'harvest,',\n",
       " u'slave',\n",
       " u'i?',\n",
       " u'makebelive',\n",
       " u'dust',\n",
       " u'older',\n",
       " u'i',\n",
       " u'well',\n",
       " u'thought',\n",
       " u'motherbecause',\n",
       " u'whonts',\n",
       " u'the',\n",
       " u'believe.\"',\n",
       " u'just',\n",
       " u'being',\n",
       " u'storey',\n",
       " u'still...dancing',\n",
       " u'yes',\n",
       " u'mother',\n",
       " u'thinking',\n",
       " u'maria\"',\n",
       " u'hay',\n",
       " u'i\\u2019d',\n",
       " u'around',\n",
       " u'i\\u2019m',\n",
       " u'mop',\n",
       " u'mom',\n",
       " u'store.',\n",
       " u'bit',\n",
       " u'said,\"hey',\n",
       " u'like',\n",
       " u'?i,myself,had',\n",
       " u'liks',\n",
       " u'stoped',\n",
       " u'berrys.',\n",
       " u'because',\n",
       " u'old',\n",
       " u'people',\n",
       " u'some',\n",
       " u'playmake',\n",
       " u'shes',\n",
       " u'playin',\n",
       " u'thinks',\n",
       " u'for',\n",
       " u'text,\"\\u201caren\\u2019t',\n",
       " u'does',\n",
       " u'be',\n",
       " u'paragraph.',\n",
       " u'makbelieve?',\n",
       " u'mite',\n",
       " u'on',\n",
       " u'of',\n",
       " u'story).',\n",
       " u'stop.',\n",
       " u'makebelieve?\\u201d',\n",
       " u'into',\n",
       " u'thesinging',\n",
       " u'couldnt',\n",
       " u'your',\n",
       " u'seidanglelike',\n",
       " u'marie',\n",
       " u'her',\n",
       " u'aren',\n",
       " u'question',\n",
       " u'hey',\n",
       " u'makebelive?\"',\n",
       " u'makebelieve.\".',\n",
       " u'lot',\n",
       " u'makebelieve?\"',\n",
       " u'was',\n",
       " u'happy',\n",
       " u'buy',\n",
       " u'eleven.',\n",
       " u'but',\n",
       " u'with',\n",
       " u'he',\n",
       " u'pretend.',\n",
       " u'youlittle',\n",
       " u'up',\n",
       " u'pretend?',\n",
       " u'disrespectful.',\n",
       " u'am',\n",
       " u'an',\n",
       " u'as',\n",
       " u'at',\n",
       " u'song.',\n",
       " u'when',\n",
       " u'actors',\n",
       " u'holding',\n",
       " u'you',\n",
       " u'star',\n",
       " u'adult?',\n",
       " u'belive',\n",
       " u'stung,\\u201d',\n",
       " u'berryies.',\n",
       " u'pail.',\n",
       " u'(west',\n",
       " u'time',\n",
       " u'wasarent']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert output of sigmoid function to its derivative -- should I?\n",
    "\n",
    "def clean_up_sentence(sentence):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    # stem each word\n",
    "    #sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
    "    sentence_words = [word.lower() for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "def bow(sentence, words, show_details=False):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # bag of words\n",
    "    bag = [0]*len(words)  \n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s: \n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "\n",
    "    return(np.array(bag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_list_59 = []\n",
    "for x in training_data_59:\n",
    "    sentence = x['text']\n",
    "    in_list_59.append(bow(sentence.lower(),words_59))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "684"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(50, 3), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# samples, features. 121 sammples. 214 features.\n",
    "clf_59 = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(50, 3), random_state=1)\n",
    "clf_59.fit(np.array(in_list_59),np.array([x['score'] for x in training_data_59])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5824742268041238"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list_59 = []\n",
    "for x in training_data_59:\n",
    "    sentence = x['text']\n",
    "    train_list_59.append(bow(sentence.lower(),words_59))\n",
    "    \n",
    "float(sum([x==y for x,y in zip(clf_59.predict(np.array(train_list_59)),y_train_59.values)]))/len(y_train_59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5979381443298969"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_59 = SVC()\n",
    "\n",
    "svm_59.fit(np.array(in_list_59),np.array([x['score'] for x in training_data_59])) \n",
    "float(np.sum([x==y for x,y in zip(svm_59.predict(np.array(train_list_59)),y_train_59.values)]))/len(y_train_59.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6326530612244898"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NN\n",
    "test_list_59 = []\n",
    "for x in testing_data_59:\n",
    "    sentence = x['text']\n",
    "    test_list_59.append(bow(sentence.lower(),words_59))\n",
    "float(np.sum([x==y for x,y in zip(clf_59.predict(np.array(test_list_59)),y_test_59.values)]))/len(y_test_59.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.673469387755102"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "float(np.sum([x==y for x,y in zip(svm_59.predict(np.array(test_list_59)),y_test_59.values)]))/len(y_test_59.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.0'], \n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_59.predict(bow(\"We're WHAT? What am I? Slave labor?\", words_59).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.75'], \n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_59.predict(bow(\"Arent you old to play make-believe?\", words_59).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarangof/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:21: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['1.0'], \n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_59.predict(bow(\"Monica asks, “‘Arent you a little old to be playing make-believe?’”\",words_59).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.0'], \n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_59.predict(bow(\"Does not say anything\",words_59).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.0'], \n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "svm_59.predict(bow(\"We're WHAT? What am I? Slave labor?\", words_59).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1.0'], \n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_59.predict(bow(\"Arent you old to play make-believe?\", words_59).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarangof/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:21: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['1.0'], \n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_59.predict(bow(\"Monica asks, “‘Arent you a little old to be playing make-believe?’”\",words_59).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.0'], \n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_59.predict(bow(\"Does not say anything\",words_59).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_list_60 = []\n",
    "for x in training_data_60:\n",
    "    sentence = x['text']\n",
    "    in_list_60.append(bow(sentence.lower(),words_60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(500, 30), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# samples, features. 121 sammples. 214 features.\n",
    "clf_60 = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(500, 30), random_state=1)\n",
    "clf_60.fit(np.array(in_list_60),np.array([x['score'] for x in training_data_60])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list_60 = []\n",
    "for x in training_data_60:\n",
    "    sentence = x['text']\n",
    "    train_list_60.append(bow(sentence.lower(),words_60))\n",
    "float(np.sum([x==y for x,y in zip(clf_60.predict(np.array(train_list_60)),y_train_60.values)]))/len(y_train_60.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6494845360824743"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_60 = SVC()\n",
    "\n",
    "svm_60.fit(np.array(in_list_60),np.array([x['score'] for x in training_data_60])) \n",
    "float(np.sum([x==y for x,y in zip(svm_60.predict(np.array(train_list_60)),y_train_60.values)]))/len(y_train_60.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for x,y,z in zip(clf_60.predict(np.array(train_list_60)),y_train_60.values,[zz['text'] for zz in training_data_60]):\n",
    "#    print(y,x,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7755102040816326"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list_60 = []\n",
    "for x in testing_data_60:\n",
    "    sentence = x['text']\n",
    "    test_list_60.append(bow(sentence.lower(),words_60))\n",
    "float(np.sum([x==y for x,y in zip(clf_60.predict(np.array(test_list_60)),y_test_60.values)]))/len(y_test_60.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6938775510204082"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(np.sum([x==y for x,y in zip(svm_60.predict(np.array(test_list_60)),y_test_60.values)]))/len(y_test_60.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.0'], \n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_60.predict(bow(\"She is happy\",words_60).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1.0'], \n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_60.predict(bow(\"She smiles\",words_60).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1.0'], \n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_60.predict(bow(\"Monica smiles\",words_60).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1.0'], \n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_60.predict(bow(\"She is happy\",words_60).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1.0'], \n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_60.predict(bow(\"She smiles\",words_60).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1.0'], \n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_60.predict(bow(\"Monica smiles\",words_60).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_list_61 = []\n",
    "for x in training_data_61:\n",
    "    sentence = x['text']\n",
    "    in_list_61.append(bow(sentence.lower(),words_61))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(50, 30), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# samples, features. 121 sammples. 214 features.\n",
    "clf_61 = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(50, 30), random_state=1)\n",
    "clf_61.fit(np.array(in_list_61),np.array([x['score'] for x in training_data_61])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVM\n",
    "svm_61 = SVC(kernel='poly')\n",
    "#‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5567010309278351"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list_61 = []\n",
    "for x in training_data_61:\n",
    "    sentence = x['text']\n",
    "    train_list_61.append(bow(sentence.lower(),words_61))\n",
    "float(np.sum([x==y for x,y in zip(clf_61.predict(np.array(train_list_61)),y_train_61.values)]))/len(y_train_61.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6494845360824743"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_61.fit(np.array(in_list_61),np.array([x['score'] for x in training_data_61])) \n",
    "float(np.sum([x==y for x,y in zip(svm_61.predict(np.array(train_list_61)),y_train_61.values)]))/len(y_train_61.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4489795918367347"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list_61 = []\n",
    "for x in testing_data_61:\n",
    "    sentence = x['text']\n",
    "    test_list_61.append(bow(sentence.lower(),words_61))\n",
    "    \n",
    "float(np.sum([x==y for x,y in zip(clf_61.predict(np.array(test_list_61)),y_test_61.values)]))/len(y_test_61.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6938775510204082"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list_61 = []\n",
    "for x in testing_data_61:\n",
    "    sentence = x['text']\n",
    "    test_list_61.append(bow(sentence.lower(),words_61))\n",
    "    \n",
    "float(np.sum([x==y for x,y in zip(svm_61.predict(np.array(test_list_61)),y_test_61.values)]))/len(y_test_61.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.0'], \n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_61.predict(bow(\"\",words_61).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1.0'], \n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_61.predict(bow(\"Monica's response changed because of what happened when she went blueberry picking with her mother. She started having fun when she was singing and dancing under the branches. So she understood why her mom sang and danced for fun at the end of the story. Also, Monica got stung by a bee, and her mom took care of her by hugging her and giving her first aid cream. So at the end of the story, she wasn't annoyed at her mom anymore.\",words_61).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.0'], \n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_61.predict(bow(\"Monica smiled\",words_61).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1.0'], \n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_61.predict(bow(\"Monica's response changed because of what happened when she went blueberry picking with her mother. She started having fun when she was singing and dancing under the branches. So she understood why her mom sang and danced for fun at the end of the story. Also, Monica got stung by a bee, and her mom took care of her by hugging her and giving her first aid cream. So at the end of the story, she wasn't annoyed at her mom anymore.\",words_61).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1.0'], \n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_61.predict(bow(\"Monica smiled\",words_61).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'take a nap.', u'hums west side story',\n",
       "       u'Monica smiles at her mom ', u'she sckooped ice cream',\n",
       "       u'Instead of grumbling about the song, Monica smiles, and goes to sleep.',\n",
       "       u'when Monica hears her mom singing to West Side Story she smiles.',\n",
       "       u'Sing along.', u'Monica smiles', u'Anorse it and say mene stuff',\n",
       "       u'When Monica hears her mother singing along to West side story. (at the end.)Monica smiles.',\n",
       "       u'when Monica hears her mother singing along to west side story at the end of the story the thing she does is she starts to smile.',\n",
       "       u'monico starts humming the song her mom was singing',\n",
       "       u'when her mother started to sing againthis time she just smiled.',\n",
       "       u'Monica to west side story and does exactly what her mother does.',\n",
       "       u'shegaveheraid creamforthefirsttime',\n",
       "       u'The thing Monica does when she hears her mother singing along to West Side Story at the end of the story is smile.',\n",
       "       u'when Monica hearsher mom she smiles i knowthis because the article says \" but i hear my mom singing to west side story and i smiled . ',\n",
       "       u'it made her smile', u'sing with her mom',\n",
       "       u'Monica smiles because she kind of had a great day.',\n",
       "       u'she says that no matter how old you are you play pretend',\n",
       "       u'Smiles'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_61[[x==y for x,y in zip(clf_61.predict(np.array(test_list_61)),y_test_61.values)]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0',\n",
       "       '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0',\n",
       "       '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0',\n",
       "       '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_61[[x==y for x,y in zip(svm_61.predict(np.array(test_list_61)),y_test_61.values)]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ u'When she hears her mother singing along to West Side Story at the end of the story Monica starts singing and dancing.',\n",
       "       u'hums west side story', u'monica starts singing the same song.',\n",
       "       u'she sckooped ice cream', u'she sings along ',\n",
       "       u'\\u201cAren\\u2019t you a little old to be playing make-believe?\\u201dI, myself, had given up on play-acting when I was nine. It was kid\\u2019s stuff, and I didn\\u2019t feel very much like a kid anymore. My mother, however, seemed to have absorbed everything about childhood that I\\u2019d left behind. Now she was dancing around the living room with the handle of a dust mop in her hand, held at an angle like a rock star\\u2019s microphone, singing.When I said that, though, she stopped.\\u201cHey, Monica, you like movies, right? Some people make a living out of playing make-believe.\\u201dShe wasn\\u2019t wrong. I did like movies, and actors did make a living dressing up, and pretending they were someone else. The fact that Mom was right annoyed me. I didn\\u2019t say anything, but picked up a stack of magazines that was on the kitchen floor, and put it on the table.\\u201cThanks, honey. I don\\u2019t think this dust mop could handle those.\\u201d Mom hummed a few lines of the music she had on.I liked rock best, and she liked musicals. But today was West Side Story, which I love',\n",
       "       u'Sing along.', u'Anorse it and say mene stuff',\n",
       "       u'monico starts humming the song her mom was singing',\n",
       "       u'When she hears her mom sing she wants to sing to because at first she thought that making believe was for babies.Then she thought it was not.For example u probably still make believe. Probablyshe was pretending to be a singer like her mom in the story.',\n",
       "       u'shegaveheraid creamforthefirsttime', u'hummes along with her',\n",
       "       u'sing with her mom', u'dance with her', u'to got a food iek'], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_61[[x!=y for x,y in zip(svm_61.predict(np.array(test_list_61)),y_test_61.values)]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0',\n",
       "       '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0',\n",
       "       '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0',\n",
       "       '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0',\n",
       "       '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0',\n",
       "       '1.0', '1.0', '1.0', '1.0'], \n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_61.predict(np.array(test_list_61))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1.0', '1.0', '0.0', '0.25', '0.5', '1.0', '0.0', '0.0', '0.0',\n",
       "       '0.0', '0.0', '0.0', '0.0', '0.5', '1.0', '1.0', '1.0', '0.0',\n",
       "       '0.0', '1.0', '0.0', '1.0', '0.0', '1.0', '0.5', '0.0', '1.0',\n",
       "       '1.0', '1.0', '0.5', '0.5', '0.0', '1.0', '1.0', '0.5', '0.25',\n",
       "       '1.0', '0.5', '0.0', '0.5', '0.5', '0.0', '1.0', '0.0', '1.0',\n",
       "       '1.0', '1.0', '0.0', '1.0'], \n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_61.predict(np.array(test_list_61))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.5', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0',\n",
       "       '0.75', '0.0', '0.0', '0.0', '0.0', '0.0'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_61[[x!=y for x,y in zip(svm_61.predict(np.array(test_list_61)),y_test_61.values)]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0',\n",
       "       '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0',\n",
       "       '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0',\n",
       "       '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0',\n",
       "       '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0', '1.0',\n",
       "       '1.0', '1.0', '1.0', '1.0'], \n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_61.predict(np.array(test_list_61))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'bielive',\n",
       " u'mom',\n",
       " u'just',\n",
       " u'being',\n",
       " u'text',\n",
       " u'over',\n",
       " u'paragraph',\n",
       " u'beleve',\n",
       " u'go',\n",
       " u'make-belieive',\n",
       " u'yes',\n",
       " u'probbly',\n",
       " u'trouble',\n",
       " u'help',\n",
       " u'beleive',\n",
       " u'makebeileve',\n",
       " u'thinking',\n",
       " u'harvest',\n",
       " u'had',\n",
       " u'young',\n",
       " u'passage',\n",
       " u'better',\n",
       " u'to',\n",
       " u'going',\n",
       " u'believing',\n",
       " u'dressing',\n",
       " u'playingmake-believe',\n",
       " u'jumped',\n",
       " u'he',\n",
       " u'into',\n",
       " u'loved',\n",
       " u'morther',\n",
       " u'monica',\n",
       " u'them',\n",
       " u'someone',\n",
       " u'around',\n",
       " u'disrespectful',\n",
       " u'get',\n",
       " u'very',\n",
       " u'stung',\n",
       " u'mop',\n",
       " u'stop',\n",
       " u'stor',\n",
       " u'begging',\n",
       " u'\\u201ci',\n",
       " u'par.1',\n",
       " u'storey',\n",
       " u'they',\n",
       " u'not',\n",
       " u'labor',\n",
       " u'bit',\n",
       " u'now',\n",
       " u'begening',\n",
       " u'is.hermotherlovewestsidestory',\n",
       " u'like',\n",
       " u'playin',\n",
       " u'stop/quit',\n",
       " u\"are'nt\",\n",
       " u'berrys',\n",
       " u'liks',\n",
       " u'stopped',\n",
       " u'she',\n",
       " u'rock',\n",
       " u'told',\n",
       " u'where',\n",
       " u'side',\n",
       " u'likes',\n",
       " u'few',\n",
       " u'right',\n",
       " u'old',\n",
       " u\"''are\",\n",
       " u\"''now\",\n",
       " u'doing',\n",
       " u'house',\n",
       " u'danicing',\n",
       " u'some',\n",
       " u'make-balieve',\n",
       " u'playmake',\n",
       " u'see',\n",
       " u'are',\n",
       " u'star',\n",
       " u'purtending',\n",
       " u'littlie',\n",
       " u'best',\n",
       " u'out',\n",
       " u'blue',\n",
       " u'living',\n",
       " u'what',\n",
       " u'said',\n",
       " u'this.\\u201d',\n",
       " u'for',\n",
       " u'micro',\n",
       " u'holdiding',\n",
       " u'please',\n",
       " u'stops',\n",
       " u'bleave',\n",
       " u'acting',\n",
       " u'version',\n",
       " u'diddent',\n",
       " u'then',\n",
       " u'got',\n",
       " u'before',\n",
       " u'?',\n",
       " u'mak-believe',\n",
       " u'be',\n",
       " u'we',\n",
       " u'who',\n",
       " u'bluederes',\n",
       " u'quit',\n",
       " u'were',\n",
       " u'story',\n",
       " u'here',\n",
       " u'kicking',\n",
       " u'blueberries',\n",
       " u'will',\n",
       " u'houm',\n",
       " u'ask',\n",
       " u'sing',\n",
       " u'picking',\n",
       " u'pretend',\n",
       " u'beginning',\n",
       " u'after',\n",
       " u'kitchen',\n",
       " u'on',\n",
       " u'great',\n",
       " u'kids',\n",
       " u'her',\n",
       " u'of',\n",
       " u'could',\n",
       " u'craziness',\n",
       " u'slave',\n",
       " u'according',\n",
       " u'ups',\n",
       " u'thing',\n",
       " u'nothing',\n",
       " u'berry',\n",
       " u'pick',\n",
       " u'think',\n",
       " u'mad',\n",
       " u'does',\n",
       " u'liked',\n",
       " u'love',\n",
       " u'dont',\n",
       " u'suddenly',\n",
       " u'i\\u2019d',\n",
       " u'hearing',\n",
       " u'hers',\n",
       " u'thesinging',\n",
       " u'because',\n",
       " u'done',\n",
       " u'stoped',\n",
       " u'make-belive',\n",
       " u'youlittle',\n",
       " u'says',\n",
       " u'humming',\n",
       " u'\\u201cyeah\\u2026but',\n",
       " u'singing',\n",
       " u'your',\n",
       " u'anwser',\n",
       " u'little',\n",
       " u'danceing',\n",
       " u'i\\u2019m',\n",
       " u'asks',\n",
       " u'make-be',\n",
       " u'aren',\n",
       " u'west',\n",
       " u'caught',\n",
       " u'people',\n",
       " u'question',\n",
       " u'hey',\n",
       " u'seidanglelike',\n",
       " u'eleven',\n",
       " u'anddancing',\n",
       " u'music',\n",
       " u'too',\n",
       " u'lot',\n",
       " u'hug',\n",
       " u'was',\n",
       " u'blueberry',\n",
       " u'store',\n",
       " u'happy',\n",
       " u'``',\n",
       " u'buy',\n",
       " u'that',\n",
       " u'nervase',\n",
       " u'.if',\n",
       " u'listing',\n",
       " u'but',\n",
       " u'else',\n",
       " u'annoyed',\n",
       " u'phone',\n",
       " u'needed',\n",
       " u'singingand',\n",
       " u'adult',\n",
       " u'...',\n",
       " u'didnt',\n",
       " u'talked',\n",
       " u'believe',\n",
       " u'with',\n",
       " u'than',\n",
       " u'blueberrys',\n",
       " u'11',\n",
       " u'also',\n",
       " u'myself',\n",
       " u'lave',\n",
       " u'aren\\u2019t',\n",
       " u'whonts',\n",
       " u'this',\n",
       " u'type',\n",
       " u'kichion',\n",
       " u'childeren',\n",
       " u'up',\n",
       " u\"n't\",\n",
       " u'movies',\n",
       " u'while',\n",
       " u\"'re\",\n",
       " u'nine',\n",
       " u'can',\n",
       " u'fills',\n",
       " u'making',\n",
       " u'animated',\n",
       " u'my',\n",
       " u'askes',\n",
       " u'shes',\n",
       " u'and',\n",
       " u'that\\xb4s',\n",
       " u'would',\n",
       " u'sees',\n",
       " u'do',\n",
       " u'almost',\n",
       " u'lines',\n",
       " u'is',\n",
       " u'allowed',\n",
       " u'am',\n",
       " u'it',\n",
       " u'an',\n",
       " u\"''\",\n",
       " u'middle',\n",
       " u'as',\n",
       " u\"aren'tyou\",\n",
       " u'at',\n",
       " u'have',\n",
       " u'in',\n",
       " u'seen',\n",
       " u'\\u201d',\n",
       " u'tells',\n",
       " u'if',\n",
       " u'grown',\n",
       " u'microphone',\n",
       " u'end',\n",
       " u'mite',\n",
       " u'dancing',\n",
       " u'saw',\n",
       " u'make',\n",
       " u'song',\n",
       " u'when',\n",
       " u'thinks',\n",
       " u'\\u201caren\\u2019t',\n",
       " u'moms',\n",
       " u'actors',\n",
       " u'holding',\n",
       " u'givenup',\n",
       " u'you',\n",
       " u'sead',\n",
       " u'pretending',\n",
       " u'makebelieve',\n",
       " u'arent',\n",
       " u'play',\n",
       " u\"'s\",\n",
       " u'motherbecause',\n",
       " u'pail',\n",
       " u'though',\n",
       " u'still',\n",
       " u'farmer',\n",
       " u'time',\n",
       " u'make-',\n",
       " u'belive',\n",
       " u'berryies',\n",
       " u\"'d\",\n",
       " u'tipped',\n",
       " u'shetells',\n",
       " u'never',\n",
       " u'anwsered',\n",
       " u'dust',\n",
       " u'marie',\n",
       " u'mam',\n",
       " u'why',\n",
       " u'maria',\n",
       " u'a',\n",
       " u'making-believe',\n",
       " u'older',\n",
       " u'i',\n",
       " u'age',\n",
       " u'well',\n",
       " u\"''what\",\n",
       " u'asked',\n",
       " u'thought',\n",
       " u'hay',\n",
       " u'clean',\n",
       " u'mother',\n",
       " u'make-believe',\n",
       " u'the',\n",
       " u'first',\n",
       " u'playing']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
